{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe08b8d",
   "metadata": {},
   "source": [
    "# qwen + sliding chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ef841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kunuru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading content...\n",
      "✂️ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Assistant: Hello! I'm here to support you with anything on your mind today. How are you feeling?\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): Lately, I’ve been feeling really anxious about small things — like I keep worrying all day about things that probably won’t even happen. It’s making me restless, and I can’t focus on my work or enjoy things like I used to. What should I do?\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "When we encounter challenges such as these, especially when they seem so overwhelming at first glance, taking some time for selfreflection and acknowledging our emotions can help us gain clarity and perspective.\n",
      "Letting go of perfectionism around tiny details might also give us permission to acknowledge that there will always be something unfulfilled or uncertain.\n",
      "Here are a few suggestions:\n",
      "1.\n",
      "Self-awareness: Take some quiet moments each evening where you reflect on how you perceive yourself right now.\n",
      "Ask yourself questions like \"What am I afraid of?\n",
      "Am I living up to expectations?\" These introspective exercises can reveal hidden fears and anxieties contributing to anxiety levels.\n",
      "2.\n",
      "Acknowledge thoughts: Notice any negative thought patterns related to those little worries.\n",
      "Are there specific scenarios or situations\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): Thank you for these suggestions. I haven’t really tried reflecting like that before. Sometimes my thoughts just keep spinning and it feels hard to stop. Could you maybe tell me some quick ways to calm down when I start feeling like this?\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "You're welcome!\n",
      "Reflecting on emotions and managing them can indeed help alleviate anxiety.\n",
      "Here are a few tips:\n",
      "1.\n",
      "Deep breathing exercises: Take slow deep breaths through your nose.\n",
      "Inhale deeply for a count of four hold for two counts and then exhale slowly for another four.\n",
      "Repeat several times throughout the day until you notice an improvement.\n",
      "2.\n",
      "Progressive muscle relaxation: tense each muscle group in turn starting from your toes up to your head.\n",
      "As you relax those muscles try imagining they are being released one by one.\n",
      "This practice helps reduce tension and promote overall relaxation.\n",
      "3.\n",
      "Mindfulness meditation: Spend a few minutes every morning or evening practicing mindfulness meditation where you stay fully present in the moment focusing solely on your senses such as\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): Thanks, that sounds helpful. I’m a bit nervous to try meditation because my mind just keeps wandering, but I’ll try the breathing exercises first. How often should I do them?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 57. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "When starting new practices like mindfulness or meditation there can sometimes be initial resistance as our minds tend to wander easily during these processes.\n",
      "However, regular consistency has been shown to improve focus and reduce anxiety over time.\n",
      "Here’s how we encourage beginners:\n",
      "1.\n",
      "Start small: Begin by setting aside dedicated time each day for practicing deep breathing exercises even if they seem effortless at first.\n",
      "You could set reminders on your phone or use an alarm clock so you always remember to take care of yourself mentally before bedtime.\n",
      "2.\n",
      "Find something comfortable: Make sure the space where you practice isn’t too stimulating or distracting.\n",
      "It might help to create a calming environment such as dimming lights making noiseless rooms or having headphones turned off while listening to soothing music.\n",
      "3.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: bye\n",
      "❗ Please enter 1 for 👍, 0 for 😐, or -1 for 👎.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): exit\n",
      "👋 Bye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# -----------------------------\n",
    "# 📤 Text Loaders\n",
    "# -----------------------------\n",
    "\n",
    "def extract_text_from_web(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = '\\n'.join(p.get_text() for p in soup.find_all(['p', 'li']))\n",
    "        return re.sub(r'\\n+', '\\n', text).strip()\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def extract_texts_from_folder(folder_path):\n",
    "    texts = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Sentence-Level Sliding Chunking\n",
    "# -----------------------------\n",
    "\n",
    "def sliding_window_chunking(text, window_size=3, overlap=1):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        chunk = ' '.join(sentences[i:i+window_size])\n",
    "        chunks.append(chunk)\n",
    "        if i + window_size >= len(sentences):\n",
    "            break\n",
    "        i += window_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 🔍 Embedding & Retrieval\n",
    "# -----------------------------\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, model_name='mindpadi/intent_encoder'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed(self, texts):\n",
    "        return self.model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, dim):\n",
    "        self.index = faiss.IndexHNSWFlat(dim, 32)\n",
    "        self.chunks = []\n",
    "\n",
    "    def add(self, embeddings, texts):\n",
    "        self.index.add(embeddings)\n",
    "        self.chunks.extend(texts)\n",
    "\n",
    "    def search(self, query_embedding, top_k=5):\n",
    "        _, idxs = self.index.search(query_embedding, top_k)\n",
    "        return [self.chunks[i] for i in idxs[0]]\n",
    "\n",
    "# -----------------------------\n",
    "# ✂️ Summarization\n",
    "# -----------------------------\n",
    "\n",
    "def load_summarizer(model_name='facebook/bart-large-cnn'):\n",
    "    return pipeline('summarization', model=model_name)\n",
    "\n",
    "def summarize_text(summarizer, text, max_len=60):\n",
    "    return summarizer(text, max_length=max_len, min_length=20, do_sample=False)[0]['summary_text']\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Prompt Template (Empathetic)\n",
    "# -----------------------------\n",
    "\n",
    "def build_prompt(context, question):\n",
    "    return f\"\"\"You are a kind and empathetic mental health assistant. Your goal is to make the user feel heard, validated, and supported.\n",
    "   - Be clear, concise, and warm. Speak like a friend, not a textbook.\n",
    "   - If you are unsure or the information is not in the context, say \"I'm not sure\" or \"I don't know\" rather than guessing.\n",
    "   - Always respond directly to what the user is feeling or asking.    \n",
    "Do NOT provide clinical jargon or speculative analysis. Instead, respond with short, clear, and compassionate language, like a trusted friend.\n",
    "Focus on validating the user's feelings, showing understanding, and gently suggesting helpful next steps without giving medical advice.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User says: \"{question}\"\n",
    "\n",
    "Your response:\"\"\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Generator\n",
    "# -----------------------------\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, trust_remote_code=True, torch_dtype=torch.float16, device_map=\"auto\"\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate(self, prompt, max_tokens=150):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        input_length = inputs.input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                temperature=0.6,\n",
    "                top_p=0.85,\n",
    "                repetition_penalty=1.2,\n",
    "                max_new_tokens=max_tokens,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        # Decode only newly generated tokens, excluding prompt\n",
    "        generated_tokens = output[0][input_length:]\n",
    "        text = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "        return text\n",
    "\n",
    "# -----------------------------\n",
    "# 📋 RLHF Feedback Logging\n",
    "# -----------------------------\n",
    "\n",
    "def log_feedback(question, answer, rating, log_file=\"feedback_log.csv\"):\n",
    "    exists = os.path.isfile(log_file)\n",
    "    with open(log_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not exists:\n",
    "            writer.writerow([\"timestamp\", \"question\", \"answer\", \"rating\"])\n",
    "        writer.writerow([datetime.now().isoformat(), question, answer, rating])\n",
    "\n",
    "# -----------------------------\n",
    "# 🚀 Build System\n",
    "# -----------------------------\n",
    "\n",
    "def build_system(txt_folder, urls, generator_model_path):\n",
    "    print(\"📥 Loading content...\")\n",
    "    docs = extract_texts_from_folder(txt_folder) + [extract_text_from_web(url) for url in urls]\n",
    "\n",
    "    print(\"✂️ Chunking...\")\n",
    "    chunks = []\n",
    "    for doc in docs:\n",
    "        chunks.extend(sliding_window_chunking(doc))\n",
    "\n",
    "    embedder = Embedder()\n",
    "    embeddings = embedder.embed(chunks)\n",
    "\n",
    "    store = VectorStore(dim=embeddings.shape[1])\n",
    "    store.add(embeddings, chunks)\n",
    "\n",
    "    summarizer = load_summarizer()\n",
    "    generator = Generator(generator_model_path)\n",
    "\n",
    "    return embedder, store, summarizer, generator\n",
    "\n",
    "# -----------------------------\n",
    "# 💬 Chat Loop with Feedback\n",
    "# -----------------------------\n",
    "\n",
    "def chat(embedder, store, summarizer, generator):\n",
    "    print(\"🤖 Assistant: Hello! I'm here to support you with anything on your mind today. How are you feeling?\")\n",
    "    previous_question = None\n",
    "    while True:\n",
    "        user_q = input(\"\\n🧠 Ask a question (type 'exit' to quit): \")\n",
    "        if user_q.lower().strip() == 'exit':\n",
    "            print(\"👋 Bye!\")\n",
    "            break\n",
    "\n",
    "        context_chunks = []\n",
    "        if previous_question:\n",
    "            context_to_summarize = f\"Previously, the user mentioned: {previous_question}\"\n",
    "            short_context = summarize_text(summarizer, context_to_summarize)\n",
    "            context_chunks.append(short_context)\n",
    "\n",
    "        query_emb = embedder.embed([user_q])\n",
    "        context_chunks += store.search(query_emb, top_k=4)\n",
    "\n",
    "        prompt = build_prompt('\\n'.join(context_chunks), user_q)\n",
    "        answer = generator.generate(prompt)\n",
    "\n",
    "        print(\"\\n🤖 Assistant:\\n\")\n",
    "        print('\\n'.join(re.split(r'(?<=[.?!]) +', answer)))\n",
    "\n",
    "        # Simplified RLHF Feedback\n",
    "        while True:\n",
    "            feedback = input(\"\\nWas this response helpful? [👍=1, 😐=0, 👎=-1]: \").strip()\n",
    "            if feedback in ['1', '0', '-1']:\n",
    "                rating = int(feedback)\n",
    "                break\n",
    "            else:\n",
    "                print(\"❗ Please enter 1 for 👍, 0 for 😐, or -1 for 👎.\")\n",
    "\n",
    "        log_feedback(user_q, answer, rating)\n",
    "        previous_question = user_q\n",
    "\n",
    "# -----------------------------\n",
    "# 🔧 Initialize\n",
    "# -----------------------------\n",
    "\n",
    "txt_folder = \"pdfs\"\n",
    "web_urls = [\n",
    "    \"https://www.apa.org/topics/anxiety/disorders\",\n",
    "    \"https://www.ncbi.nlm.nih.gov/books/NBK558911/\"\n",
    "]\n",
    "model_path = \"qwen2.5-0.5B_finetuned_mentalhealth\"\n",
    "\n",
    "embedder, store, summarizer, generator = build_system(txt_folder, web_urls, model_path)\n",
    "chat(embedder, store, summarizer, generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf44e5d",
   "metadata": {},
   "source": [
    "### after breaking at fullstop + dynamic summarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a9e3bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 19:03:29.661086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-18 19:03:30.380272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-18 19:03:30.380397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-05-18 19:03:30.380407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-18 19:03:31,863] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "[nltk_data] Downloading package punkt to /home/kunuru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading content...\n",
      "✂️ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Assistant: Hello! I'm here to support you with anything on your mind today. How are you feeling?\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): I’ve been feeling really anxious lately, and it’s hard to focus on anything. I don’t even know why I feel this way.\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "It sounds like you’re experiencing some anxiety right now and it might be helpful for you to take care of yourself first before dealing with any additional concerns such as difficulties focusing online.\n",
      "Here are some suggestions that could help alleviate your symptoms:\n",
      "1.\n",
      "Practice deep breathing exercises: Take slow deep breaths several times throughout the day when you start feeling overwhelmed by stress.\n",
      "Deep breathing can actually calm down your nervous system helping you stay calmer.\n",
      "2.\n",
      "Try meditation or mindfulness practices: Mindfulness involves being present without judgment which has been shown to reduce anxiety levels.\n",
      "You can try guided meditations apps like Headspace or simply setting aside specific time each day to practice mindful awareness while observing your thoughts and sensations.\n",
      "3.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): Thanks, I haven’t really tried meditation before. I’m worried it might be hard to stick with it though. What if I can’t do it right?\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "Let me try my best to help without sounding too clinical or pushy.\n",
      "You’re asking about starting something new such as practicing mindfulness or meditating which could potentially be challenging initially but also rewarding once mastered.\n",
      "Here are some tips:\n",
      "1.\n",
      "Start small Try incorporating short periods into daily routine rather than setting up an entire practice at once.\n",
      "Consistency tends to lead to better outcomes over time.\n",
      "2.\n",
      "Find comfort find moments where you naturally gravitate towards relaxation activities.\n",
      "This could involve things like taking a walk outside enjoying nature finding joy in doing crossword puzzles writing poems etc.\n",
      "When we seek solace within ourselves through these experiences our minds will become more receptive to positive thoughts and behaviors.\n",
      "3.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): That makes sense. I guess I could try starting small. But sometimes I feel really down and hopeless, like nothing will ever get better. I don’t know how to handle those moments.\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "It seems like you want some guidance about managing difficult emotions such as feeling stuck or helpless when dealing with setbacks or challenges.\n",
      "Starting small and being patient while building resilience can help mitigate these feelings.\n",
      "Here’s an approach you might consider:\n",
      "1.\n",
      "Acknowledge Your Feelings:\n",
      "   Take a moment to acknowledge the difficulty you’re experiencing.\n",
      "Recognize that it takes time and effort to overcome obstacles even without immediate relief.\n",
      "Sometimes we underestimate our capacity for growth because we believe things would improve quickly but they take longer than expected.\n",
      "2.\n",
      "Set Small Goals:\n",
      "   Break larger issues into smaller manageable pieces.\n",
      "Start by setting achievable goals rather than pushing yourself too far at once.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): I appreciate that. Sometimes I get overwhelmed by negative thoughts, and it feels like they keep spiraling. How can I stop this cycle when it happens?\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "It sounds like coping with overwhelming negative thoughts might require some effort but also patience.\n",
      "Here are a few strategies that may help:\n",
      "1.\n",
      "Practice selfcare take care of yourself emotionally physically and mentally before attempting new challenges.\n",
      "engaging in activities that bring you joy and relaxation can alleviate stress levels which contribute to these negative emotions.\n",
      "Try practicing mindfulness meditation deep breathing exercises or even journaling for brief periods each day.\n",
      "2.\n",
      "Challenge negative thought patterns identify whether certain beliefs or assumptions underlie these negative thoughts.\n",
      "Take time to reflect on why such statements occur so that you recognize their underlying causes.\n",
      "Once identified challenge them with evidence supporting alternative perspectives or facts that align with reality.\n",
      "3.\n",
      "Seek support connect with others who understand similar struggles.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): Thank you. I think talking to someone might help, but I don’t really know how to start that conversation. I’m scared they won’t understand.\n",
      "\n",
      "🤖 Assistant:\n",
      "\n",
      "You’re right; starting such conversations about overcoming challenges takes courage.\n",
      "Here’s an encouraging approach:\n",
      "1.\n",
      "**Prepare yourself:** It’s important to prepare for the conversation ahead of time.\n",
      "Take some deep breaths before setting up the discussion so you feel more confident and less anxious during the interaction.\n",
      "2.\n",
      "**Be open and honest:** Begin by being as upfront as possible regarding your situation.\n",
      "Explain why you’ve been feeling overwhelmed lately and tell them directly where these emotions originate.\n",
      "This honesty will set a good tone for the conversation and show sincerity.\n",
      "3.\n",
      "**Use active listening skills** When discussing challenges or struggles, try focusing on their experiences rather than dwelling on the problem itself.\n",
      "Let the other person share theirs own perspective without getting defensive or critical.\n",
      "\n",
      "Was this response helpful? [👍=1, 😐=0, 👎=-1]: 1\n",
      "\n",
      "🧠 Ask a question (type 'exit' to quit): exit\n",
      "👋 Bye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# -----------------------------\n",
    "# 📤 Text Loaders\n",
    "# -----------------------------\n",
    "\n",
    "def extract_text_from_web(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = '\\n'.join(p.get_text() for p in soup.find_all(['p', 'li']))\n",
    "        return re.sub(r'\\n+', '\\n', text).strip()\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def extract_texts_from_folder(folder_path):\n",
    "    texts = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Sentence-Level Sliding Chunking\n",
    "# -----------------------------\n",
    "\n",
    "def sliding_window_chunking(text, window_size=3, overlap=1):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        chunk = ' '.join(sentences[i:i+window_size])\n",
    "        chunks.append(chunk)\n",
    "        if i + window_size >= len(sentences):\n",
    "            break\n",
    "        i += window_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 🔍 Embedding & Retrieval\n",
    "# -----------------------------\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, model_name='mindpadi/intent_encoder'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed(self, texts):\n",
    "        return self.model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, dim):\n",
    "        self.index = faiss.IndexHNSWFlat(dim, 32)\n",
    "        self.chunks = []\n",
    "\n",
    "    def add(self, embeddings, texts):\n",
    "        self.index.add(embeddings)\n",
    "        self.chunks.extend(texts)\n",
    "\n",
    "    def search(self, query_embedding, top_k=5):\n",
    "        _, idxs = self.index.search(query_embedding, top_k)\n",
    "        return [self.chunks[i] for i in idxs[0]]\n",
    "\n",
    "# -----------------------------\n",
    "# ✂️ Summarization (Dynamic)\n",
    "# -----------------------------\n",
    "def load_summarizer(model_name='facebook/bart-large-cnn'):\n",
    "    return pipeline('summarization', model=model_name)\n",
    "\n",
    "def summarize_text(summarizer, text):\n",
    "    length = len(text.split())\n",
    "\n",
    "    # Skip summarization for short inputs\n",
    "    if length < 50:\n",
    "        return text\n",
    "\n",
    "    # Dynamically calculate summary length\n",
    "    max_len = min(120, max(30, length // 3))\n",
    "    min_len = max(20, max_len // 2)\n",
    "\n",
    "    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)[0]['summary_text']\n",
    "    return summary\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Prompt Template (Empathetic)\n",
    "# -----------------------------\n",
    "\n",
    "def build_prompt(context, question):\n",
    "    return f\"\"\"You are a kind and empathetic mental health assistant.\n",
    "Speak like a trusted friend: short, clear, warm, and non-clinical.\n",
    "\n",
    "Rules:\n",
    "- Avoid long apologies or excessive reassurance.\n",
    "- Validate the user's feelings in one or two friendly sentences.\n",
    "- Don't give medical advice.\n",
    "- If unsure, say “I’m not sure.”\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User says: \"{question}\"\n",
    "\n",
    "Your response:\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Generator (with sentence trimming)\n",
    "# -----------------------------\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, trust_remote_code=True, torch_dtype=torch.float16, device_map=\"auto\"\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate(self, prompt, max_tokens=150):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        input_length = inputs.input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "                max_new_tokens=max_tokens,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        # Decode only newly generated tokens, excluding prompt\n",
    "        generated_tokens = output[0][input_length:]\n",
    "        text = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "\n",
    "        # Trim output to last complete sentence\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "        if len(sentences) > 1:\n",
    "            last_sentence = sentences[-1]\n",
    "            if not re.search(r'[.!?]$', last_sentence):\n",
    "                # Drop incomplete last sentence\n",
    "                sentences = sentences[:-1]\n",
    "            text = ' '.join(sentences).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "# -----------------------------\n",
    "# 📋 RLHF Feedback Logging\n",
    "# -----------------------------\n",
    "\n",
    "def log_feedback(question, answer, rating, log_file=\"feedback_log.csv\"):\n",
    "    exists = os.path.isfile(log_file)\n",
    "    with open(log_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not exists:\n",
    "            writer.writerow([\"timestamp\", \"question\", \"answer\", \"rating\"])\n",
    "        writer.writerow([datetime.now().isoformat(), question, answer, rating])\n",
    "\n",
    "# -----------------------------\n",
    "# 🚀 Build System\n",
    "# -----------------------------\n",
    "\n",
    "def build_system(txt_folder, urls, generator_model_path):\n",
    "    print(\"📥 Loading content...\")\n",
    "    docs = extract_texts_from_folder(txt_folder) + [extract_text_from_web(url) for url in urls]\n",
    "\n",
    "    print(\"✂️ Chunking...\")\n",
    "    chunks = []\n",
    "    for doc in docs:\n",
    "        chunks.extend(sliding_window_chunking(doc))\n",
    "\n",
    "    embedder = Embedder()\n",
    "    embeddings = embedder.embed(chunks)\n",
    "\n",
    "    store = VectorStore(dim=embeddings.shape[1])\n",
    "    store.add(embeddings, chunks)\n",
    "\n",
    "    summarizer = load_summarizer()\n",
    "    generator = Generator(generator_model_path)\n",
    "\n",
    "    return embedder, store, summarizer, generator\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 💬 Chat Loop with Feedback\n",
    "# -----------------------------\n",
    "def chat(embedder, store, summarizer, generator):\n",
    "    print(\"🤖 Assistant: Hello! I'm here to support you with anything on your mind today. How are you feeling?\")\n",
    "    previous_question = None\n",
    "    while True:\n",
    "        user_q = input(\"\\n🧠 Ask a question (type 'exit' to quit): \")\n",
    "        if user_q.lower().strip() == 'exit':\n",
    "            print(\"👋 Bye!\")\n",
    "            break\n",
    "\n",
    "        context_chunks = []\n",
    "        if previous_question:\n",
    "            context_to_summarize = f\"Previously, the user mentioned: {previous_question}\"\n",
    "            short_context = summarize_text(summarizer, context_to_summarize)  # ✅ dynamic summary\n",
    "            context_chunks.append(short_context)\n",
    "\n",
    "        query_emb = embedder.embed([user_q])\n",
    "        context_chunks += store.search(query_emb, top_k=4)\n",
    "\n",
    "        prompt = build_prompt('\\n'.join(context_chunks), user_q)\n",
    "        answer = generator.generate(prompt)\n",
    "\n",
    "        print(\"\\n🤖 Assistant:\\n\")\n",
    "        print('\\n'.join(re.split(r'(?<=[.?!]) +', answer)))\n",
    "\n",
    "        while True:\n",
    "            feedback = input(\"\\nWas this response helpful? [👍=1, 😐=0, 👎=-1]: \").strip()\n",
    "            if feedback in ['1', '0', '-1']:\n",
    "                rating = int(feedback)\n",
    "                break\n",
    "            else:\n",
    "                print(\"❗ Please enter 1 for 👍, 0 for 😐, or -1 for 👎.\")\n",
    "\n",
    "        log_feedback(user_q, answer, rating)\n",
    "        previous_question = user_q\n",
    "\n",
    "# -----------------------------\n",
    "# 🔧 Initialize\n",
    "# -----------------------------\n",
    "\n",
    "txt_folder = \"pdfs\"\n",
    "web_urls = [\n",
    "    \"https://www.apa.org/topics/anxiety/disorders\",\n",
    "    \"https://www.ncbi.nlm.nih.gov/books/NBK558911/\"\n",
    "]\n",
    "model_path = \"qwen2.5-0.5B_finetuned_mentalhealth\"\n",
    "\n",
    "embedder, store, summarizer, generator = build_system(txt_folder, web_urls, model_path)\n",
    "chat(embedder, store, summarizer, generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2fe3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6fd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a5671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25b610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3281e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b23274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c4806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1173c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
